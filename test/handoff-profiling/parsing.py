#!/usr/bin/env python
import sys
import os
import ast
from pprint import pprint
from collections import defaultdict
from collections import OrderedDict
from operator import itemgetter
import matplotlib.pyplot as plt
from matplotlib import rcParams
import matplotlib


stage_names = ["CreateMemoryDeltalist", "CreateDiskDeltalist", "DeltaDedup", "CompressProc"]


class ProfilingError(Exception):
    pass


class Experiment(object):
    def __init__(self):
        pass

    def __repr__(self):
        return "%s,R:%s,P:%s" % (self.workload, self.get_total_R(), self.get_total_P())

    def get_total_P(self):
        # get processing time per block using total time of stages

        #memory_in_size = self.stage_size_in['CreateMemoryDeltalist']
        #disk_in_size = self.stage_size_in['CreateDiskDeltalist']
        #alpha = float(memory_in_size)/(memory_in_size+disk_in_size)

        disk_diff = self.stage_time['CreateMemoryDeltalist']
        memory_diff = self.stage_time['CreateDiskDeltalist']
        delta = self.stage_time['DeltaDedup']
        comp = self.stage_time['CompressProc']

        # should not weight using alpha
        # calculate using p of all stages --> use alpha
        # calculate using time at all stage --> do not use alpha
        total_processing_time = memory_diff+disk_diff+delta+comp 
        total_block = self.block['CreateDiskDeltalist'] + self.block['CreateMemoryDeltalist']
        total_p_block = float(total_processing_time) / total_block
        return total_p_block*1000

    def estimate_total_P(self):
        # estimate processing time per block using block processing time of each stage
        # calculate using p of all stages --> use alpha
        # calculate using time at all stage --> do not use alpha
        memory_in_size = self.stage_size_in['CreateMemoryDeltalist']
        disk_in_size = self.stage_size_in['CreateDiskDeltalist']
        alpha = float(memory_in_size)/(memory_in_size+disk_in_size)
        total_P_from_each_stage = (self.block_time['CreateMemoryDeltalist']*alpha + self.block_time['CreateDiskDeltalist']*(1-alpha))\
            + self.block_time['DeltaDedup'] + self.block_time['CompressProc']
        return total_P_from_each_stage

    def get_total_R(self):
        disk_diff = self.stage_size_in['CreateMemoryDeltalist']
        memory_diff = self.stage_size_in['CreateDiskDeltalist']
        comp = self.stage_size_out['CompressProc']
        total_R = float(comp)/(disk_diff+memory_diff)
        return round(total_R, 4)

    def estimate_total_R(self):
        # weight using input size
        memory_in_size = self.stage_size_in['CreateMemoryDeltalist']
        disk_in_size = self.stage_size_in['CreateDiskDeltalist']
        alpha = float(memory_in_size)/(memory_in_size+disk_in_size)
        total_R_from_each_stage = (self.block_size_ratio['CreateMemoryDeltalist']*alpha +\
                                   self.block_size_ratio['CreateDiskDeltalist']*(1-alpha))\
                                * self.block_size_ratio['DeltaDedup']\
                                * self.block_size_ratio['CompressProc']
        return total_R_from_each_stage

    @staticmethod
    def mode_diff_str(exp1, exp2):
        mode1 = exp1.mode
        mode2 = exp2.mode
        set_mode1, set_mode2= set(mode1.keys()), set(mode2.keys())
        intersect = set_mode1.intersection(set_mode2)
        changed_keys = [o for o in intersect if mode1[o] != mode2[o]]
        changed_list = list()
        for key in changed_keys:
            value1 = mode1[key]
            value2 = mode2[key]
            changed = "%s: %s->%s" % (key, value1, value2)
            changed_list.append(changed)
        changed_str = ", ".join(changed_list)
        return changed_str


def parse_each_experiement(lines):
    # get configuration
    config_lines = ""
    is_start_config_line = False
    workload = lines[0].split(" ")[-1]
    migration_total_time = 0
    migration_downtime = 0
    for line in lines[1:]:
        if line.find("* Overlay creation mode start") != -1:
            is_start_config_line = True
            continue
        if is_start_config_line == True:
            config_lines += line
            if line.find("}") != -1:
                break
    config_dict = ast.literal_eval(config_lines)

    # filter out only profiling log
    profile_lines = list()
    for line in lines:
        # see only DEBUG message
        if line.find("DEBUG") == -1:
            continue
        if line.find("profiling") != -1:
            # see only profiling message
            log = line.split("profiling")[1].strip()
            profile_lines.append(log)
        elif line.find("Time for finishing transferring") != -1:
            log = line.split(":")[-1]
            migration_total_time = float(log.strip())
        elif line.find("Finish migration") != -1:
            log = line.split(":")[-1]
            migration_total_time = float(log.strip())
        elif line.find("migration downtime") != -1:
            log = line.split(":")[-1]
            migration_downtime = float(log.strip())

    # process filtered log data
    exp = Experiment()
    workload = lines[0].split(" ")[-1]
    setattr(exp, 'workload', os.path.basename(workload))
    setattr(exp, 'migration_total_time', migration_total_time)
    setattr(exp, 'migration_downtime', migration_downtime)
    setattr(exp, 'mode', config_dict)
    setattr(exp, 'stage_size_in', dict.fromkeys(stage_names, 0))
    setattr(exp, 'stage_size_out', dict.fromkeys(stage_names, 0))
    setattr(exp, 'stage_size_ratio', dict.fromkeys(stage_names, 0))
    setattr(exp, 'stage_time', dict.fromkeys(stage_names, 0))
    setattr(exp, 'block', dict.fromkeys(stage_names, 0))
    setattr(exp, 'block_size_in', dict.fromkeys(stage_names, 0))
    setattr(exp, 'block_size_ratio', dict.fromkeys(stage_names, 0))
    setattr(exp, 'block_size_out', dict.fromkeys(stage_names, 0))
    setattr(exp, 'block_time', dict.fromkeys(stage_names, 0))
    for line in profile_lines:
        log = line.split("\t")
        stage_name = log[0]
        profile_type = str(log[1])
        if stage_name not in stage_names:
            continue
        if profile_type == "size":
            in_size = long(log[2])
            out_size = long(log[3])
            ratio = float(log[4])
            exp.stage_size_in[stage_name] = in_size
            exp.stage_size_out[stage_name] = out_size
            exp.stage_size_ratio[stage_name] = ratio
        if profile_type == "block-size":
            in_size = float(log[2])
            out_size = float(log[3])
            block_count = long(log[4])
            exp.block[stage_name] = block_count
            exp.block_size_in[stage_name] = in_size
            exp.block_size_out[stage_name] = out_size
            exp.block_size_ratio[stage_name] = out_size/float(in_size)
        if profile_type == "time":
            duration = float(log[-1])
            exp.stage_time[stage_name] = duration
        if profile_type == "block-time":
            duration = round(float(log[-1])*1000, 6)
            exp.block_time[stage_name] = duration
    return exp 

def parsing(inputfile):
    lines = open(inputfile, "r").read().split("\n")
    test_list = list()
    new_log = list()
    for line in lines:
        if line.find("==========================================") != -1:
            if len(new_log) > 0:
                test_list.append(new_log)
            new_log = list()
        else:
            new_log.append(line)
    test_list.append(new_log)

    test_ret_list = list()
    for each_exp_log in test_list:
        test_ret = parse_each_experiement(each_exp_log)
        test_ret_list.append(test_ret)
    return test_ret_list


def _split_experiment(test_ret_list):
    moped_exps = list()
    speech_exps = list()
    fluid_exps = list()
    face_exps = list()
    mar_exps = list()
    random_exps = list()
    delta_exps = list()
    for each_exp in test_ret_list:
        if each_exp.workload.find("moped") !=  -1:
            moped_exps.append(each_exp)
        elif each_exp.workload.find("fluid") !=  -1:
            fluid_exps.append(each_exp)
        elif each_exp.workload.find("face") !=  -1:
            face_exps.append(each_exp)
        elif each_exp.workload.find("mar") !=  -1:
            mar_exps.append(each_exp)
        elif each_exp.workload.find("speech") !=  -1:
            speech_exps.append(each_exp)
        elif each_exp.workload.find("random") !=  -1:
            random_exps.append(each_exp)
        elif each_exp.workload.find("delta") !=  -1:
            delta_exps.append(each_exp)
        else:
            msg = "Invalid workload %s" % each_exp['workload']
            print msg
            sys.exit(1)
            raise ProfilingError(msg)
    #if (len(moped_exps) == len(fluid_exps) == len(face_exps) == len(mar_exps)) == False:
    #    msg = "workloads have different experiement size"
    #    print msg
    #    sys.exit(1)
    #    raise ProfilingError(msg)
    return moped_exps, speech_exps, fluid_exps, face_exps, mar_exps, random_exps, delta_exps

def multikeysort(items, columns):
    comparers = [ ((itemgetter(col[1:].strip()), -1) if col.startswith('-') else (itemgetter(col.strip()), 1)) for col in columns]  
    def comparer(left, right):
        for fn, mult in comparers:
            result = cmp(fn(left), fn(right))
            if result:
                return mult * result
            else:
                return 0
    return sorted(items, cmp=comparer)


def print_bw(exps):
    # sort by compression algorithm gzip 1, .., gzip9, .., lzma1, .., lzma9
    def compare_comp_algorithm(a):
        d = {"xdelta3":3,
             "bsdiff":4,
             "xor":2,
             "none":1}
        return (d[a.mode['DISK_DIFF_ALGORITHM']], -a.mode['COMPRESSION_ALGORITHM_TYPE'], a.mode['COMPRESSION_ALGORITHM_SPEED'])
    exps.sort(key=compare_comp_algorithm)
    result_dict = OrderedDict()
    for each_exp in exps:
        in_data_size = each_exp.stage_size_in['CreateMemoryDeltalist'] + each_exp.stage_size_in['CreateDiskDeltalist']
        in_data_disk = each_exp.stage_size_in['CreateDiskDeltalist']
        in_data_mem = each_exp.stage_size_in['CreateMemoryDeltalist']
        alpha = float(in_data_mem)/in_data_size
        out_data_size = each_exp.stage_size_out['CompressProc']
        duration = each_exp.migration_total_time
        est_duration1 = each_exp.stage_time['CreateMemoryDeltalist'] + each_exp.stage_time['CreateDiskDeltalist']+\
            each_exp.stage_time['DeltaDedup'] + each_exp.stage_time['CompressProc']
        key = "%s,%d,%d" % (each_exp.mode['DISK_DIFF_ALGORITHM'], each_exp.mode['COMPRESSION_ALGORITHM_TYPE'],each_exp.mode['COMPRESSION_ALGORITHM_SPEED'])
        value = (in_data_size, out_data_size, duration, 8*float(out_data_size)/1024.0/1024/duration)
        item_list = result_dict.get(key, list())
        item_list.append(value)
        result_dict[key] = item_list

        #print "%s,%d,%d\t%ld\t%ld\t%f,%f,%f\t%f" %\
        #    (each_exp.mode['DISK_DIFF_ALGORITHM'],\
        #    each_exp.mode['COMPRESSION_ALGORITHM_TYPE'],\
        #     each_exp.mode['COMPRESSION_ALGORITHM_SPEED'],\
        #     in_data_size, out_data_size, duration, est_duration1, float(duration)/est_duration1,
        #     8*float(out_data_size)/1024.0/1024/duration) 

    # chose the median throughput value
    for (key, value_list) in result_dict.iteritems():
        value_list.sort(key=itemgetter(3))
        value_len = len(value_list)
        value = value_list[value_len/2]
        print "%s\t%s\t%s\t%s\t%s" % ("\t".join(key.split(",")), value[0], value[1], value[2], value[3])


def sort_experiment_by_diff_compress(exps):
    def compare_comp_algorithm(a):
        d = {"xdelta3":3,
             "bsdiff":4,
             "xor":2,
             "none":1}
        return (d[a.mode['DISK_DIFF_ALGORITHM']], -a.mode['COMPRESSION_ALGORITHM_TYPE'], a.mode['COMPRESSION_ALGORITHM_SPEED'])
    exps.sort(key=compare_comp_algorithm)
    return exps


def print_bw_block(exps):
    # sort by compression algorithm gzip 1, .., gzip9, .., lzma1, .., lzma9
    exps = sort_experiment_by_diff_compress(exps)
    result_dict = OrderedDict()
    for each_exp in exps:
        in_data_size = each_exp.stage_size_in['CreateMemoryDeltalist'] + each_exp.stage_size_in['CreateDiskDeltalist']
        in_data_disk = each_exp.stage_size_in['CreateDiskDeltalist']
        in_data_mem = each_exp.stage_size_in['CreateMemoryDeltalist']
        alpha = float(in_data_mem)/in_data_size
        out_data_size = each_exp.stage_size_out['CompressProc']
        duration = each_exp.migration_total_time
        est_duration = each_exp.stage_time['CreateMemoryDeltalist'] + each_exp.stage_time['CreateDiskDeltalist']+\
            each_exp.stage_time['DeltaDedup'] + each_exp.stage_time['CompressProc']
        est_duration += 14# serial part
        total_r = each_exp.get_total_R()
        total_p = each_exp.get_total_P()
        total_r_est = each_exp.estimate_total_R()
        total_p_est = each_exp.estimate_total_P()
        key = "%s,%d,%d" % (each_exp.mode['DISK_DIFF_ALGORITHM'], each_exp.mode['COMPRESSION_ALGORITHM_TYPE'],each_exp.mode['COMPRESSION_ALGORITHM_SPEED'])
        value = (in_data_size, out_data_size, duration, est_duration,
                 8*float(out_data_size)/1024.0/1024/duration,
                 total_p, total_r, total_p_est, total_r_est)
        item_list = result_dict.get(key, list())
        item_list.append(value)
        result_dict[key] = item_list

        #print "%s,%d,%d\t%ld\t%ld\t%f,%f,%f\t%f\t%f,%f\t%f,%f" %\
        #    (each_exp.mode['DISK_DIFF_ALGORITHM'],\
        #    each_exp.mode['COMPRESSION_ALGORITHM_TYPE'],\
        #     each_exp.mode['COMPRESSION_ALGORITHM_SPEED'],\
        #     in_data_size, out_data_size, duration, est_duration, float(duration)/est_duration1,
        #     8*float(out_data_size)/1024.0/1024/duration,\
        #     total_p, total_p_est,
        #     total_r, total_r_est)

    # chose the median throughput value
    for (key, value_list) in result_dict.iteritems():
        value_list.sort(key=itemgetter(3))
        value_len = len(value_list)
        (insize, outsize, duration, est_duration, bw, total_p, total_r, total_p_est, total_r_est) = value_list[value_len/2]
        print "%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s" % ("\t".join(key.split(",")),
                                                      insize, outsize, duration,
                                                      est_duration,
                                                      float(duration)/float(est_duration),
                                                      bw, total_p, total_r)

def averaged_pr(measure_history, duration):
    avg_p = float(0)
    avg_r = float(0)
    counter = 0
    (cur_time, cur_p, cur_r) = measure_history[-1]
    for (measured_time, p, r) in reversed(measure_history):
        if cur_time - measured_time > duration:
            break
        avg_p += p
        avg_r += r
        counter += 1
    #print "%f measure last %d/%d" % (cur_time, counter, len(measure_history))
    return avg_p/counter, avg_r/counter


def averaged_value(measure_hist, cur_time, avg_time=1):
    avg_value = float(0)
    counter = 0
    for (measured_time, value) in reversed(measure_hist):
        if cur_time - measured_time > avg_time:
            break
        avg_value += float(value)
        counter += 1
    #LOG.debug("coutning for avg : %d" % counter)
    return float(avg_value)/counter


def print_p_r_over_time(inputfile):
    lines = open(inputfile, "r").read().split("\n")
    adaptation_log_lines = list()
    mode_test_log_lines = list()
    mode_change_log_lines = list()
    for line in lines:
        # see only DEBUG message
        if line.find("DEBUG") == -1:
            continue
        if line.find("adaptation") != -1:
            # see only profiling message
            log = line.split("adaptation")[1].strip()
            adaptation_log_lines.append(log)
        if line.find("mode-change-test") != -1:
            log = line.split("mode-change-test")[1].strip()
            mode_test_log_lines.append(log)
        if line.find("mode-change") != -1 and line.find("mode-change-test") == -1:
            log = line.split("mode-change")[1].strip()
            mode_change_log_lines.append(log)

    migration_start_time = 0
    system_in_hist = list()
    system_out_hist = list()
    iteration_time_list = list()
    p_and_r_list = list()
    measure_history = list()
    time_list = list()
    p_list = list()
    p_list_cur = list()
    r_list = list()
    r_list_cur = list()
    network_bw_list = list()
    system_in_bw_list = list()
    system_out_bw_list = list()
    system_out_bw_potential_list = list()
    for line in adaptation_log_lines:
        if line.startswith("start time"):
            migration_start_time = float(line.split(":")[-1])
        elif line.startswith("new iteration"):
            iter_time, iter_seq_old, iter_seq_new, iter_mem_size = line.split("\t")[1:]
            iteration_time_list.append((iter_seq_old, iter_time))
        else:
            (time_measured, duration_measured, network_bw_mbps,\
             system_out_bw_actual, system_in_bw_actual,\
             system_out_bw_cur_est, system_in_bw_cur_est,\
             total_p, total_r,\
             total_p_cur, total_r_cur) = line.split("\t")
            p_and_r_list.append((duration_measured, total_p, total_p_cur, total_r, total_r_cur))
            measure_history.append((float(duration_measured), float(total_p_cur), float(total_r_cur)))
            network_bw_list.append(network_bw_mbps)

            # data for plot
            duration = float(time_measured)-float(migration_start_time)
            time_list.append(duration)
            #time_list.append(duration_measured)
            p_list.append(float(total_p))
            p_list_cur.append(float(total_p_cur))
            r_list.append(float(total_r))
            r_list_cur.append(float(total_r_cur))
            system_out_bw_potential_list.append(float(system_out_bw_cur_est))

            system_in_hist.append((float(time_measured), system_in_bw_actual))
            system_out_hist.append((float(time_measured), system_out_bw_actual))
            system_in_actual_avg = averaged_value(system_in_hist, float(time_measured), avg_time=2)
            system_out_actual_avg = averaged_value(system_out_hist, float(time_measured), avg_time=2)
            #system_in_actual_avg = system_in_bw_actual
            #system_out_actual_avg = system_out_bw_actual
            system_in_bw_list.append(system_in_actual_avg)
            system_out_bw_list.append(system_out_actual_avg)

    # averaged p and r over time window
    p_list_avg1 = list()
    p_list_avg2 = list()
    r_list_avg1 = list()
    r_list_avg2 = list()
    for index, (duration_measured, total_p_cur, total_r_cur) in enumerate(measure_history):
        avg_p1, avg_r1 = averaged_pr(measure_history[0:index+1], 1)
        avg_p2, avg_r2 = averaged_pr(measure_history[0:index+1], 5)
        p_list_avg1.append(avg_p1)
        p_list_avg2.append(avg_p2)

    # print result
    print "iter #\tduration\ttime"
    for index, (iter_seq_old, iter_time) in enumerate(iteration_time_list):
        print "%s\t%f\t%s" % (iter_seq_old, (float(iter_time)-float(migration_start_time)), iter_time)
    print "\n\n"
    print "duration\ttotal_p\tcur_p\ttotal_r\tcur_r"
    for values in p_and_r_list:
        (duration_measured, total_p, total_p_cur, total_r, total_r_cur) = values
        print "%s\t%s\t%s\t%s\t%s" % (duration_measured, total_p, total_p_cur, total_r, total_r_cur)


    # figure plot
    fig, ax = plt.subplots()
    font = {'family' : 'Times New Roman',
            'weight' : 'normal',
            'size'   : 22}
    matplotlib.rc('font', **font)

    # plot p and r
    f1, (p_plot, r_plot)= plt.subplots(2, 1, sharex=True)
    p_plot.set_title("P - " + inputfile)
    r_plot.set_title("R - " + inputfile)
    p_plot.plot(time_list, p_list, 'r-', time_list, p_list_cur, 'b-')
    r_plot.plot(time_list, r_list, 'r-', time_list, r_list_cur, 'b-')
    cur_xlim = f1.gca().get_xlim()[1]
    p_plot.set_xlim([0, cur_xlim])
    (y_min, y_max) = p_plot.get_ylim()
    p_plot.set_ylim([0, max(1, y_max)])
    r_plot.set_ylim([0, 1])
    plt.savefig(inputfile + "-pr" + '.png')


    # plot performance
    f2, (bw_plot)= plt.subplots(1, 1, sharex=True)
    f2.set_size_inches(12,5)
    bw_plot.set_ylabel("Throughput (MBps)")
    bw_plot.set_xlabel("Time (s)")
    bw_plot.set_title("Trace - " + inputfile)
    LINE_WIDTH = 3
    bw_plot.plot(time_list, system_in_bw_list, 'r-o', label="input throughput", linewidth=LINE_WIDTH)
    bw_plot.plot(time_list, system_out_bw_list, 'b-+', label="Output throughput", linewidth=LINE_WIDTH)
    bw_plot.plot(time_list, system_out_bw_potential_list, 'b--', label="Potential output throughput", linewidth=LINE_WIDTH)
    bw_plot.plot(time_list, network_bw_list, 'g-', label="Network throughput", linewidth=LINE_WIDTH-1)
    bw_plot.set_xlim([0, cur_xlim])
    #bw_plot.legend(shadow=True, bbox_to_anchor=(0., 1.02, 1., .102), loc=3)
    bw_plot.legend(shadow=True, loc="best", prop={'size':18})

    # plot mode change if it exists
    for each_mode_change in mode_change_log_lines:
        if each_mode_change.lower().find("current mode is the best") != -1:
            continue
        mode_change_time = float(each_mode_change.split("\t")[0]) - migration_start_time
        #mode_change_time = float(each_mode_change.split("\t")[1])
        bw_plot.axvline(x=mode_change_time, linewidth=2, color='k', linestyle='-.')
    f2.gca().grid(True)
    #bw_plot.axhline(y=network_bw, linewidth=1, color='g', linestyle='--')
    plt.gcf().subplots_adjust(bottom=0.15)
    #plt.gcf().subplots_adjust(left=0.01)
    plt.savefig(inputfile + "-bw" + '.png')


if __name__ == "__main__":
    command_list = ["profiling", "over-time", "summary"]
    if len(sys.argv) != 3:
        sys.stderr.write("Need command(%s) and input filename\n" % (','.join(command_list)))
        sys.exit(1)
    command = sys.argv[1]
    inputfile = sys.argv[2]

    if command == "profiling":
        test_ret_list = parsing(inputfile)
        moped_exps, speech_exps, fluid_exps, face_exps, mar_exps, random_exps, delta_exps = _split_experiment(test_ret_list)
        #print_bw(face_exps)
        print_bw_block(moped_exps)
    elif command == "over-time":
        print_p_r_over_time(inputfile)
    elif command == "summary":
        exp_list = parsing(inputfile)
        exp = exp_list[0]
        workload = exp.workload
        in_size = exp.stage_size_in['CreateMemoryDeltalist'] + exp.stage_size_in['CreateDiskDeltalist']
        out_size = exp.stage_size_in['CompressProc']
        handoff_time = exp.migration_total_time
        migration_downtime = exp.migration_downtime
        total_ratio = (float(out_size)/in_size)
        total_cpu_time = sum(exp.stage_time.values())
        system_in_bw = 8*float(in_size)/handoff_time/1024.0/1024.0
        system_out_bw = 8*float(out_size)/handoff_time/1024.0/1024.0
        print "workload: %s (%s)" % (inputfile, workload)
        print "total\tdown\tcpu\tin-size\tout\tin-bw\tout-bw"
        print "%4.2f\t%4.2f\t%4.2f\t%6.2f\t%6.2f\t%6.2f\t%6.2f" % (handoff_time, migration_downtime, total_cpu_time, in_size/1024.0/1024, out_size/1024.0/1024, system_in_bw, system_out_bw)



    else:
        pass
        '''
        # how change in mode will affect system performance?
        comparison = defaultdict(list)
        pivot_mode = moped_exps[0]
        pivot_R = pivot_mode.get_total_R()
        pivot_P = pivot_mode.get_total_P()
        for other_mode in moped_exps:
            other_r = other_mode.get_total_R()
            other_p = other_mode.get_total_P()
            ratio_r = round(other_r/pivot_R, 4)
            ratio_p = round(other_p/pivot_P, 4)
            mode_diff_str = Experiment.mode_diff_str(pivot_mode, other_mode)
            if len(mode_diff_str) == 0:
                mode_diff_str = "original"
            comparison[mode_diff_str].append((ratio_r, ratio_p))
            #print "%s\t%s %s" % (mode_diff_str, ratio_r, ratio_p)
        '''
